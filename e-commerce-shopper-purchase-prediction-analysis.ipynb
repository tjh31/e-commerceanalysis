{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":893685,"sourceType":"datasetVersion","datasetId":477512}],"dockerImageVersionId":30513,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/tanishaharde/e-commerce-shopper-purchase-prediction-analysis?scriptVersionId=167187673\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"> ## **<center>Problem Statement:</center>** \n>   Marketing teams constantly strive to optimize their promotions, pricing, \npersonalization, and campaigns to increase customer acquisition, retention, and \nrevenue. However, identifying the most effective strategies can be challenging. \nMachine learning algorithms can be used to analyze past customer behavior and \npredict future outcomes based on various marketing strategies.\n\n>The aim of this project is **to develop a machine learning model that can predict whether a customer visiting an online shopping website will make a purchase or not. This prediction can help marketing teams in optimizing their promotions, pricing, personalization, and campaigns to increase the likelihood of purchase and ultimately, revenue.**\n***","metadata":{}},{"cell_type":"markdown","source":"## **<center> Justification and Source of Dataset :  </center>** \n\n>The \"Online Shoppers Purchasing Intention Dataset\" from UCI Machine Learning \nRepository is a suitable dataset for this problem statement. This dataset contains various features related to user behavior on an online shopping website, such as the number of pages visited, the duration of the visit, and the type of traffic source. The dataset also includes a binary label indicating whether the user made a purchase or not.\n\n>This dataset is suitable for solving this problem because it provides insights into \nvarious factors that influence the purchasing decision of users on an online \nshopping website. By analyzing this data, machine learning models can learn to \nidentify the most effective marketing strategies for increasing the likelihood of purchase\n\n","metadata":{}},{"cell_type":"markdown","source":"### Importing libraries and files : ###","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom ydata_profiling import ProfileReport\n\n%matplotlib inline\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T09:59:25.742366Z","iopub.execute_input":"2023-06-22T09:59:25.742724Z","iopub.status.idle":"2023-06-22T09:59:25.749981Z","shell.execute_reply.started":"2023-06-22T09:59:25.742694Z","shell.execute_reply":"2023-06-22T09:59:25.748925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/online-shoppers-intention/online_shoppers_intention.csv')","metadata":{"execution":{"iopub.status.busy":"2023-06-22T09:59:27.966021Z","iopub.execute_input":"2023-06-22T09:59:27.966382Z","iopub.status.idle":"2023-06-22T09:59:27.992714Z","shell.execute_reply.started":"2023-06-22T09:59:27.966356Z","shell.execute_reply":"2023-06-22T09:59:27.991234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-22T09:59:29.080212Z","iopub.execute_input":"2023-06-22T09:59:29.080771Z","iopub.status.idle":"2023-06-22T09:59:29.100726Z","shell.execute_reply.started":"2023-06-22T09:59:29.080748Z","shell.execute_reply":"2023-06-22T09:59:29.099152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2023-06-22T09:59:30.782358Z","iopub.execute_input":"2023-06-22T09:59:30.782715Z","iopub.status.idle":"2023-06-22T09:59:30.815429Z","shell.execute_reply.started":"2023-06-22T09:59:30.782688Z","shell.execute_reply":"2023-06-22T09:59:30.814078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2023-06-22T09:59:33.32192Z","iopub.execute_input":"2023-06-22T09:59:33.322298Z","iopub.status.idle":"2023-06-22T09:59:33.336159Z","shell.execute_reply.started":"2023-06-22T09:59:33.322271Z","shell.execute_reply":"2023-06-22T09:59:33.334915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(df.columns)","metadata":{"execution":{"iopub.status.busy":"2023-06-22T09:59:35.502986Z","iopub.execute_input":"2023-06-22T09:59:35.503337Z","iopub.status.idle":"2023-06-22T09:59:35.509161Z","shell.execute_reply.started":"2023-06-22T09:59:35.5033Z","shell.execute_reply":"2023-06-22T09:59:35.508317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":">The decision to drop certain columns from the dataset depends on the specific analysis goals and the relevance of each column to those goals. \n\n>In this case, I decided to drop the 'Administrative', 'Informational', and 'ProductRelated' columns because they represent the number of pages visited by the user in each of these categories, and the total number of pages visited is already captured by the 'PageValues' column. Therefore, these columns were considered redundant and not useful for the analysis. ","metadata":{}},{"cell_type":"code","source":"df = df.drop(['Administrative', 'Informational', 'ProductRelated'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-06-22T09:59:37.634927Z","iopub.execute_input":"2023-06-22T09:59:37.635292Z","iopub.status.idle":"2023-06-22T09:59:37.641708Z","shell.execute_reply.started":"2023-06-22T09:59:37.635263Z","shell.execute_reply":"2023-06-22T09:59:37.640783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(df.columns)","metadata":{"execution":{"iopub.status.busy":"2023-06-22T09:59:38.269555Z","iopub.execute_input":"2023-06-22T09:59:38.270631Z","iopub.status.idle":"2023-06-22T09:59:38.276859Z","shell.execute_reply.started":"2023-06-22T09:59:38.270587Z","shell.execute_reply":"2023-06-22T09:59:38.275963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":">In the dataset, there are some columns with categorical variables, such as 'Month', 'VisitorType', 'OperatingSystem', and 'Browser'.\n\n>Machine learning algorithms generally require numerical inputs, so we need to convert these categorical variables into numerical format.\n\n>**Label encoding** and **one-hot encoding** are two techniques to achieve this conversion","metadata":{}},{"cell_type":"markdown","source":">**Label encoding** assigns a unique numerical value to each category of a variable. For example, for the 'Month' column, we can assign a numerical value of 1 for January, 2 for February, and so on. Label encoding is suitable for categorical variables that have a natural ordering, such as 'Month' and 'VisitorType'.\n\n>One-hot encoding, on the other hand, creates a new binary column for each category of a variable. \n","metadata":{}},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n<b>Note:</b> Here, we will be using <b>Label encoding </b>             \n</div>","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder","metadata":{"execution":{"iopub.status.busy":"2023-06-22T09:59:41.261301Z","iopub.execute_input":"2023-06-22T09:59:41.261625Z","iopub.status.idle":"2023-06-22T09:59:41.265706Z","shell.execute_reply.started":"2023-06-22T09:59:41.261603Z","shell.execute_reply":"2023-06-22T09:59:41.265212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We have imported LabelEncoding above","metadata":{}},{"cell_type":"code","source":"categorical_columns=['Weekend','Revenue']\nfor col in categorical_columns:\n    encoder = LabelEncoder()\n    encoder.fit(df[col])\n    print('Column:', col)\n    print('Original categories:', encoder.classes_)\n    print('Encoded values:', encoder.transform(encoder.classes_))\n    print('\\n')\n    df[col] = encoder.fit_transform(df[col])\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T09:59:43.474963Z","iopub.execute_input":"2023-06-22T09:59:43.475273Z","iopub.status.idle":"2023-06-22T09:59:43.486717Z","shell.execute_reply.started":"2023-06-22T09:59:43.475252Z","shell.execute_reply":"2023-06-22T09:59:43.484971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndf['Month'] = df['Month'].map({'Feb': 2, 'Mar': 3, 'May': 5,'June':6,'Jul':7,'Aug':8,'Sep':9,'Oct':10,'Nov':11,'Dec':12})\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T09:59:44.206062Z","iopub.execute_input":"2023-06-22T09:59:44.206407Z","iopub.status.idle":"2023-06-22T09:59:44.21369Z","shell.execute_reply.started":"2023-06-22T09:59:44.206381Z","shell.execute_reply":"2023-06-22T09:59:44.212281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-06-22T09:59:45.174923Z","iopub.execute_input":"2023-06-22T09:59:45.17527Z","iopub.status.idle":"2023-06-22T09:59:45.191092Z","shell.execute_reply.started":"2023-06-22T09:59:45.175245Z","shell.execute_reply":"2023-06-22T09:59:45.190439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Next, let's explore the duplicated data.","metadata":{}},{"cell_type":"code","source":"df.duplicated().value_counts()  #to see the count of duplicated rows","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-06-22T09:59:47.591404Z","iopub.execute_input":"2023-06-22T09:59:47.591765Z","iopub.status.idle":"2023-06-22T09:59:47.611503Z","shell.execute_reply.started":"2023-06-22T09:59:47.591737Z","shell.execute_reply":"2023-06-22T09:59:47.610408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n<b>Note:</b> <b> False:</b> implies number of rows without any duplicates.<br>\n           <b> True:</b> implies number of rows with duplicates\n</div>","metadata":{}},{"cell_type":"markdown","source":"### Now, we will see the duplicated rows: ","metadata":{}},{"cell_type":"code","source":"# Use the `duplicated` function to identify duplicated rows\nduplicated_rows = df[df.duplicated()]\n\n# Print the duplicated rows\nprint(duplicated_rows)","metadata":{"execution":{"iopub.status.busy":"2023-06-22T09:59:49.250137Z","iopub.execute_input":"2023-06-22T09:59:49.250496Z","iopub.status.idle":"2023-06-22T09:59:49.272649Z","shell.execute_reply.started":"2023-06-22T09:59:49.25047Z","shell.execute_reply":"2023-06-22T09:59:49.271526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> We need to drop duplicated values from the dataset as they can affect the accuracy of the model. Duplicated values can cause bias in the data, which can lead to incorrect predictions. Hence, we will drop them before performing any analysis or building a model. ","metadata":{}},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-warning\">\nWe will be using the drop_duplicates() method from pandas to drop the duplicated values.\n</div>","metadata":{}},{"cell_type":"code","source":"df.drop_duplicates(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-06-22T09:59:52.753706Z","iopub.execute_input":"2023-06-22T09:59:52.754601Z","iopub.status.idle":"2023-06-22T09:59:52.766663Z","shell.execute_reply.started":"2023-06-22T09:59:52.754551Z","shell.execute_reply":"2023-06-22T09:59:52.765438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-info\">\n<b>Note:</b>  Here, in order to make changes in the original dataframe, we have set the \"inplace\" parameter to \"True\" while dropping duplicates. \n</div>","metadata":{}},{"cell_type":"code","source":"cols_to_scale = ['Administrative_Duration','Informational_Duration','ProductRelated_Duration','BounceRates','ExitRates','PageValues','SpecialDay']\n\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\ndf[cols_to_scale] = scaler.fit_transform(df[cols_to_scale])","metadata":{"execution":{"iopub.status.busy":"2023-06-22T09:59:55.116637Z","iopub.execute_input":"2023-06-22T09:59:55.117028Z","iopub.status.idle":"2023-06-22T09:59:55.129302Z","shell.execute_reply.started":"2023-06-22T09:59:55.117001Z","shell.execute_reply":"2023-06-22T09:59:55.128289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The MinMaxScaler is a preprocessing technique that scales all the values in a given feature to be in the range of 0 and 1. This is done to bring all the features to a common scale and avoid one feature dominating the others in a model that uses distance-based algorithms. The fit_transform() method of the scaler object fits the scaler to the data and transforms the data using the scaler in one step.","metadata":{}},{"cell_type":"markdown","source":"# EXPLORATORY DATA ANALYSIS\n To effectively communicate insights and patterns in data to facilitate understanding and decision-making.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Group the data by traffic type\ngrouped_data = df.groupby('TrafficType')\n\n# Calculate average revenue per traffic type\naverage_revenue = grouped_data['Revenue'].mean()\n\n# Calculate total revenue per traffic type\ntotal_revenue = grouped_data['Revenue'].sum()\n\n# Compare revenue across traffic types\nrevenue_comparison = pd.DataFrame({'Average Revenue': average_revenue, 'Total Revenue': total_revenue})\n\n# Print the revenue comparison\nprint(revenue_comparison)\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T10:00:02.069133Z","iopub.execute_input":"2023-06-22T10:00:02.069537Z","iopub.status.idle":"2023-06-22T10:00:02.08433Z","shell.execute_reply.started":"2023-06-22T10:00:02.069505Z","shell.execute_reply":"2023-06-22T10:00:02.082762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Sort the revenue comparison dataframe in descending order based on the revenue metric\nrevenue_comparison.sort_values(by='Total Revenue', ascending=False, inplace=True)\n\n# Visualize the sorted data\nplt.figure(figsize=(10, 6))\nsns.barplot(data=revenue_comparison, x=df['TrafficType'], y='Total Revenue')\nplt.title('Total Revenue by Traffic Type')\nplt.xlabel('Traffic Type')\nplt.ylabel('Total Revenue')\nplt.xticks(rotation=45)\nplt.show()\n\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T10:00:03.688987Z","iopub.execute_input":"2023-06-22T10:00:03.689478Z","iopub.status.idle":"2023-06-22T10:00:04.14826Z","shell.execute_reply.started":"2023-06-22T10:00:03.689454Z","shell.execute_reply":"2023-06-22T10:00:04.146728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Traffic Type 2 and Traffic Type 3 generate the highest total revenue, indicating that these two traffic sources are driving the <b> most valuable </b>  traffic to the website.<br>\nIt is important to focus on optimizing and maximizing the traffic from Traffic Type 2 and Traffic Type 3, as they have shown to be the most valuable sources of revenue for the website","metadata":{}},{"cell_type":"code","source":"\n\n# Filter the dataset for Traffic Type 2 visitors\ntraffic_type_2_data = df[df['TrafficType'] == 2]\n\n# Filter the dataset for Traffic Type 3 visitors\ntraffic_type_3_data = df[df['TrafficType'] == 3]\n\n# Demographic analysis\ndemographic_variables = ['VisitorType']\n\nfor variable in demographic_variables:\n    plt.figure(figsize=(8, 6))\n    sns.countplot(data=traffic_type_2_data, x=variable, palette='viridis')\n    plt.title(f'{variable} Distribution for Traffic Type 2 Visitors')\n    plt.xlabel(variable)\n    plt.ylabel('Count')\n    plt.show()\n\n    plt.figure(figsize=(8, 6))\n    sns.countplot(data=traffic_type_3_data, x=variable, palette='viridis')\n    plt.title(f'{variable} Distribution for Traffic Type 3 Visitors')\n    plt.xlabel(variable)\n    plt.ylabel('Count')\n    plt.show()\n\n# Behavioral analysis\nbehavioral_variables = ['PageValues', 'BounceRates', 'ExitRates']\n\nfor variable in behavioral_variables:\n    plt.figure(figsize=(8, 6))\n    sns.boxplot(data=traffic_type_2_data, x=variable, palette='viridis')\n    plt.title(f'{variable} Distribution for Traffic Type 2 Visitors')\n    plt.xlabel(variable)\n    plt.show()\n\n    plt.figure(figsize=(8, 6))\n    sns.boxplot(data=traffic_type_3_data, x=variable, palette='viridis')\n    plt.title(f'{variable} Distribution for Traffic Type 3 Visitors')\n    plt.xlabel(variable)\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T10:00:05.553083Z","iopub.execute_input":"2023-06-22T10:00:05.553452Z","iopub.status.idle":"2023-06-22T10:00:07.154457Z","shell.execute_reply.started":"2023-06-22T10:00:05.553424Z","shell.execute_reply":"2023-06-22T10:00:07.153244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the demographic analysis:\n\n- For Traffic Type 2 visitors,Visitors from Traffic Type 2 are primarily Returning Visitors.\n\n- For Traffic Type 3 visitors,Visitors from Traffic Type 3 are also primarily Returning Visitors.\n\nFrom the behavioral analysis:\n\n- The average page values for Traffic Type 2 visitors are higher compared to Traffic Type 3 visitors, indicating that visitors from Traffic Type 2 are more likely to generate revenue on the website.\n \n-The bounce rates and exit rates for Traffic Type 2 visitors are relatively low compared to other traffic types. This suggests that visitors coming from Traffic Type 2 have a higher level of engagement and are more likely to explore multiple pages before leaving the website. \nThis makes them a valuable traffic source for revenue generation.\n\n-The bounce rates and exit rates for Traffic Type 3 visitors are relatively high compared to other traffic types. \nThis suggests that visitors coming from Traffic Type 3 may have a lower engagement level with the website, leading to a higher likelihood of leaving the website without further interaction..\n\n\n\n\n\n","metadata":{}},{"cell_type":"code","source":"\n\n# Group the data by 'SpecialDay' and calculate the average revenue or visitor count\nspecial_day_analysis = df.groupby('SpecialDay')['Revenue'].mean()  # Replace 'Revenue' with the appropriate metric\n\n# Sort the data in descending order based on the average revenue or visitor count\nspecial_day_analysis = special_day_analysis.sort_values(ascending=False)\n\n# Visualize the impact of special days on customer engagement\nplt.figure(figsize=(10, 6))\nsns.barplot(x=special_day_analysis.index, y=special_day_analysis.values)\nplt.title(\"Impact of Special Days on Customer Engagement\")\nplt.xlabel(\"Special Day\")\nplt.ylabel(\"Average Revenue\" ) \nplt.xticks(rotation=45)\nplt.show()\n\n# Identify the special days with the highest impact on customer engagement\ntop_special_days = special_day_analysis.head(3)  # Replace '3' with the desired number of top special days\n\nprint(\"Special Days with the Highest Impact on Customer Engagement:\")\nfor day, impact in top_special_days.items():\n    print(f\"- {day}: {impact}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T10:00:07.668942Z","iopub.execute_input":"2023-06-22T10:00:07.669267Z","iopub.status.idle":"2023-06-22T10:00:07.940385Z","shell.execute_reply.started":"2023-06-22T10:00:07.669244Z","shell.execute_reply":"2023-06-22T10:00:07.939125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr=df.corr()\nsns.set(style='white')\nplt.figure(figsize=(8, 6))\nsns.heatmap(corr,vmin=-1, vmax=1, center=0, cmap=sns.diverging_palette(20, 220, n=200), linewidths=0.5)","metadata":{"execution":{"iopub.status.busy":"2023-06-22T10:00:10.42663Z","iopub.execute_input":"2023-06-22T10:00:10.426998Z","iopub.status.idle":"2023-06-22T10:00:11.119402Z","shell.execute_reply.started":"2023-06-22T10:00:10.426972Z","shell.execute_reply":"2023-06-22T10:00:11.118527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above correlation matrix of the online shopper dataset, we can observe that:\n\nThe 'ExitRates' and 'BounceRates' features are moderately correlated, which makes sense as both are related to the visitor leaving the website.\n\nThe 'PageValues' feature is weakly correlated with the other features, which suggests that it may not have a strong impact on predicting whether a visitor will make a purchase or not.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(9, 3))\nplt.hist(df['Revenue'],color='navy')\n\nplt.title('Revenue Class Distribution')\nplt.xlabel('Revenue')\nplt.ylabel('Count')\nplt.show()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-06-22T10:00:37.565141Z","iopub.execute_input":"2023-06-22T10:00:37.565483Z","iopub.status.idle":"2023-06-22T10:00:37.814906Z","shell.execute_reply.started":"2023-06-22T10:00:37.565457Z","shell.execute_reply":"2023-06-22T10:00:37.813892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The above visualization helps to understand the distribution of the target variable, which is the revenue class. In the case of a binary classification problem like this one, it is important to have a balanced distribution of the classes. We can observe that there is a class imbalance here which could lead to a biased model that performs poorly on the minority class. ","metadata":{}},{"cell_type":"code","source":"N=len(df)\ncolors = np.random.rand(N)\nplt.scatter(df['PageValues'], df['BounceRates'],c=colors)\nplt.title('Page Values vs. Bounce Rates')\nplt.xlabel('Page Values')\nplt.ylabel('Bounce Rates')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T10:00:40.513629Z","iopub.execute_input":"2023-06-22T10:00:40.513963Z","iopub.status.idle":"2023-06-22T10:00:40.919216Z","shell.execute_reply.started":"2023-06-22T10:00:40.513939Z","shell.execute_reply":"2023-06-22T10:00:40.917828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can observe that there is a general trend where higher page values tend to have lower bounce rates. This could indicate that users are more likely to stay on a website if the page provides them with more valuable information or products. However, there are also many data points with low page values and low bounce rates, suggesting that there may be other factors at play as well.","metadata":{}},{"cell_type":"markdown","source":"# Handling Class Imbalance","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-06-22T10:00:46.9947Z","iopub.execute_input":"2023-06-22T10:00:46.995092Z","iopub.status.idle":"2023-06-22T10:00:47.011537Z","shell.execute_reply.started":"2023-06-22T10:00:46.99506Z","shell.execute_reply":"2023-06-22T10:00:47.010782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Revenue'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-06-22T10:00:48.241724Z","iopub.execute_input":"2023-06-22T10:00:48.242584Z","iopub.status.idle":"2023-06-22T10:00:48.249561Z","shell.execute_reply.started":"2023-06-22T10:00:48.242559Z","shell.execute_reply":"2023-06-22T10:00:48.248686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X=df.drop('Revenue',axis=1)\ny=df['Revenue']","metadata":{"execution":{"iopub.status.busy":"2023-06-22T10:00:50.455609Z","iopub.execute_input":"2023-06-22T10:00:50.456253Z","iopub.status.idle":"2023-06-22T10:00:50.460775Z","shell.execute_reply.started":"2023-06-22T10:00:50.456227Z","shell.execute_reply":"2023-06-22T10:00:50.460204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42,stratify=y)","metadata":{"execution":{"iopub.status.busy":"2023-06-22T10:00:55.722849Z","iopub.execute_input":"2023-06-22T10:00:55.723252Z","iopub.status.idle":"2023-06-22T10:00:55.738374Z","shell.execute_reply.started":"2023-06-22T10:00:55.723224Z","shell.execute_reply":"2023-06-22T10:00:55.736961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-06-22T10:00:57.367588Z","iopub.execute_input":"2023-06-22T10:00:57.367966Z","iopub.status.idle":"2023-06-22T10:00:57.375111Z","shell.execute_reply.started":"2023-06-22T10:00:57.367939Z","shell.execute_reply":"2023-06-22T10:00:57.374414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-06-22T10:00:58.216304Z","iopub.execute_input":"2023-06-22T10:00:58.217415Z","iopub.status.idle":"2023-06-22T10:00:58.224746Z","shell.execute_reply.started":"2023-06-22T10:00:58.217367Z","shell.execute_reply":"2023-06-22T10:00:58.22378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-06-22T10:00:59.045762Z","iopub.execute_input":"2023-06-22T10:00:59.04612Z","iopub.status.idle":"2023-06-22T10:00:59.053751Z","shell.execute_reply.started":"2023-06-22T10:00:59.046095Z","shell.execute_reply":"2023-06-22T10:00:59.052698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape","metadata":{"execution":{"iopub.status.busy":"2023-06-22T10:01:00.344786Z","iopub.execute_input":"2023-06-22T10:01:00.345107Z","iopub.status.idle":"2023-06-22T10:01:00.351038Z","shell.execute_reply.started":"2023-06-22T10:01:00.345082Z","shell.execute_reply":"2023-06-22T10:01:00.350231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test.shape","metadata":{"execution":{"iopub.status.busy":"2023-06-22T10:01:01.188761Z","iopub.execute_input":"2023-06-22T10:01:01.189135Z","iopub.status.idle":"2023-06-22T10:01:01.196341Z","shell.execute_reply.started":"2023-06-22T10:01:01.189108Z","shell.execute_reply":"2023-06-22T10:01:01.19514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train[:10]","metadata":{"execution":{"iopub.status.busy":"2023-06-22T10:01:02.795696Z","iopub.execute_input":"2023-06-22T10:01:02.796072Z","iopub.status.idle":"2023-06-22T10:01:02.815889Z","shell.execute_reply.started":"2023-06-22T10:01:02.796043Z","shell.execute_reply":"2023-06-22T10:01:02.814352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" We'll be using *SMOTE*  technique to handle the class imbalance","metadata":{}},{"cell_type":"code","source":"\nfrom imblearn.over_sampling import SMOTE\n\n# Perform one-hot encoding on the categorical features\nX_encoded = pd.get_dummies(X)\n\n# Apply SMOTE on the encoded features and target variable\nsmote = SMOTE(sampling_strategy='minority')\nX_sm, y_sm = smote.fit_resample(X_encoded, y)\n\n# Convert the resampled target variable to a pandas Series\ny_sm = pd.Series(y_sm)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T10:01:09.141404Z","iopub.execute_input":"2023-06-22T10:01:09.141713Z","iopub.status.idle":"2023-06-22T10:01:09.252624Z","shell.execute_reply.started":"2023-06-22T10:01:09.141692Z","shell.execute_reply":"2023-06-22T10:01:09.251247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nX_train, X_test, y_train, y_test = train_test_split(X_sm, y_sm, test_size=0.2, random_state=15, stratify=y_sm)","metadata":{"execution":{"iopub.status.busy":"2023-06-22T10:01:13.694101Z","iopub.execute_input":"2023-06-22T10:01:13.694469Z","iopub.status.idle":"2023-06-22T10:01:13.709588Z","shell.execute_reply.started":"2023-06-22T10:01:13.694433Z","shell.execute_reply":"2023-06-22T10:01:13.708426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Number of classes in training Data\ny_train.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-06-22T10:01:17.041218Z","iopub.execute_input":"2023-06-22T10:01:17.041532Z","iopub.status.idle":"2023-06-22T10:01:17.048579Z","shell.execute_reply.started":"2023-06-22T10:01:17.041508Z","shell.execute_reply":"2023-06-22T10:01:17.047443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Comparing Machine learning models","metadata":{}},{"cell_type":"code","source":"import pandas as pd <br>\nfrom lazypredict.Supervised import LazyClassifier\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T09:55:08.379646Z","iopub.execute_input":"2023-06-22T09:55:08.381042Z","iopub.status.idle":"2023-06-22T09:55:08.4321Z","shell.execute_reply.started":"2023-06-22T09:55:08.380989Z","shell.execute_reply":"2023-06-22T09:55:08.430567Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf = LazyClassifier(verbose=0, ignore_warnings=True, custom_metric=None)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models,predictions = clf.fit(X_train, X_test, y_train, y_test)\n\nprint(models)\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\n\nrf = RandomForestClassifier(n_estimators=1000, random_state=1)\nrf.fit(X_train, y_train)\n\n# Make predictions on the test set and evaluate model performance\ny_pred = rf.predict(X_test)\naccuracy = accuracy_score(y_test, y_pred)\nprint(f'Accuracy: {accuracy}')\nprint(classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2023-06-22T10:01:30.905374Z","iopub.execute_input":"2023-06-22T10:01:30.905701Z","iopub.status.idle":"2023-06-22T10:01:58.887083Z","shell.execute_reply.started":"2023-06-22T10:01:30.905679Z","shell.execute_reply":"2023-06-22T10:01:58.885773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\n\n# Plot the confusion matrix as a heatmap\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-06-22T10:02:08.550753Z","iopub.execute_input":"2023-06-22T10:02:08.551121Z","iopub.status.idle":"2023-06-22T10:02:08.762784Z","shell.execute_reply.started":"2023-06-22T10:02:08.551097Z","shell.execute_reply":"2023-06-22T10:02:08.761634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.datasets import make_classification\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T10:02:17.308083Z","iopub.execute_input":"2023-06-22T10:02:17.308432Z","iopub.status.idle":"2023-06-22T10:02:17.414089Z","shell.execute_reply.started":"2023-06-22T10:02:17.308406Z","shell.execute_reply":"2023-06-22T10:02:17.412591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"et = ExtraTreesClassifier(n_estimators=100, random_state=42)\net.fit(X_train, y_train)\ny_pred = et.predict(X_test)\naccuracy_et = accuracy_score(y_test, y_pred)\nprint('Extra Trees Accuracy:', accuracy_et)\n\nprint(f'Accuracy: {accuracy_et}')\nprint(classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2023-06-22T10:02:19.437584Z","iopub.execute_input":"2023-06-22T10:02:19.43799Z","iopub.status.idle":"2023-06-22T10:02:21.266208Z","shell.execute_reply.started":"2023-06-22T10:02:19.437965Z","shell.execute_reply":"2023-06-22T10:02:21.264657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)\n\n# Plot the confusion matrix as a heatmap\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.title('Confusion Matrix')\nplt.xlabel('Predicted Label')\nplt.ylabel('True Label')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-06-22T10:02:29.069766Z","iopub.execute_input":"2023-06-22T10:02:29.071163Z","iopub.status.idle":"2023-06-22T10:02:29.286758Z","shell.execute_reply.started":"2023-06-22T10:02:29.071116Z","shell.execute_reply":"2023-06-22T10:02:29.285639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We choose the ExtraTrees Classfier predictive model as it provides maximum accuracy ( approx 94%).","metadata":{}},{"cell_type":"markdown","source":"# Time to Test!","metadata":{}},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2023-06-22T10:04:47.378277Z","iopub.execute_input":"2023-06-22T10:04:47.378629Z","iopub.status.idle":"2023-06-22T10:04:47.386133Z","shell.execute_reply.started":"2023-06-22T10:04:47.378602Z","shell.execute_reply":"2023-06-22T10:04:47.384895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will take inputs from user , and predict whether the person will buy or not.\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n# Define user input as a dictionary\nuser_input = {'Administrative_Duration': 50,\n              'Informational_Duration': 100,\n              'ProductRelated_Duration': 200,\n              'BounceRates': 0.05,\n              'ExitRates': 0.1,\n              'PageValues': 20,\n              'SpecialDay': 0,\n              'Month': 7,\n              'OperatingSystems': 0,\n              'Browser': 0,\n              'Region': 0,\n              'TrafficType': 1,\n              'VisitorType': 'New_Visitor',\n              'Weekend': 1}\n\n# Create a DataFrame from the user input dictionary\nuser_df = pd.DataFrame.from_dict(user_input, orient='index').T\n\n# Map VisitorType to binary columns\nvisitor_type_mapping = {\n    'New_Visitor': 1,\n    'Other': 0,\n    'Returning_Visitor': 0\n}\nuser_df['VisitorType_New_Visitor'] = user_df['VisitorType'].map(visitor_type_mapping)\nuser_df['VisitorType_Other'] = user_df['VisitorType'].map(visitor_type_mapping)\nuser_df['VisitorType_Returning_Visitor'] = user_df['VisitorType'].map(visitor_type_mapping)\n\n# Drop the original VisitorType column\nuser_df.drop('VisitorType', axis=1, inplace=True)\n\n# Make a prediction for the user input\nprediction = et.predict(user_df)\nprint(prediction)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-06-22T10:06:23.585787Z","iopub.execute_input":"2023-06-22T10:06:23.586149Z","iopub.status.idle":"2023-06-22T10:06:23.614692Z","shell.execute_reply.started":"2023-06-22T10:06:23.586126Z","shell.execute_reply":"2023-06-22T10:06:23.613735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It is evident that for the given set of inputs, the customer is not likely to make a purchase online.","metadata":{}},{"cell_type":"markdown","source":"Similarly, we can give the model different sets of input and predict whether a customer visiting an online shopping website will make a purchase or not. ","metadata":{}},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-warning\">\n    <b>Note: </b> Our prediction is subject to our model's accuracy which is <b> approximately </b> 94%.\n</div>","metadata":{}}]}